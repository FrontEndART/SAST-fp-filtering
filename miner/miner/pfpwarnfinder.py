#!/usr/bin/env python3

import argparse
import datetime
import itertools
import os
import pathlib
import sys
import tarfile
from io import StringIO

import pandas as pd
from alive_progress import alive_it
from git import Repo
from loguru import logger
from unidiff import PatchSet

from Transformations import report_to_dict, create_warn, get_iso_commit_date

logger.remove(0)
logger.add(
    sys.stderr,
    format="<green>{time:YYYY.MM.DD. HH:mm:ss}</green> <bold>[{level}]</bold>: {message}",
    colorize=True,
)

parser = argparse.ArgumentParser(
    prog="PMD FP warning finder tool", description="PMD FP warning finder tool"
)

parser.add_argument("--local-repo", required=True, nargs=1, type=pathlib.Path)
parser.add_argument("--tp-warn-db", required=True, nargs=1, type=pathlib.Path)
parser.add_argument("--reports", required=True, nargs=1, type=pathlib.Path)
parser.add_argument("--output", required=True, nargs=1, type=pathlib.Path)
parser.add_argument(
    "--since", required=False, nargs="?", type=datetime.date.fromisoformat
)
parser.add_argument(
    "--until", required=False, nargs="?", type=datetime.date.fromisoformat
)

args = parser.parse_args()

local_repo = str(args.local_repo[0])
tp_warn_db = str(args.tp_warn_db[0])
reports = str(args.reports[0])
output = str(args.output[0])
since = args.since if "since" in args else None
until = args.until if "until" in args else None

if not os.path.exists(local_repo):
    logger.error(f"Local repository {local_repo} does not exist.")
    exit(1)


if not os.path.exists(reports):
    logger.error("PMD reports dir {reports} does not exist.")
    exit(1)

repo = Repo(local_repo)

remote_url = repo.remotes.origin.url.split(".git")[0]

commits = list(
    repo.iter_commits(repo.head.name, reverse=True, since=since, until=until)
)

if len(commits) < 2:
    logger.warning(
        "There are no PMD FP warnings. No output was generated by PMD FP warning finder."
    )
    exit()

if os.path.exists(tp_warn_db):
    tp_warns = pd.read_csv(tp_warn_db)
    tp_warn_msgs = set(tp_warns["warning_msg"])
else:
    tp_warn_msgs = set()

warn_db = []

for i in alive_it(
    range(len(commits) - 1), title="Searching for PMD FP warnings", bar="classic"
):
    commit = commits[i]
    next_commit = commits[i + 1]

    # Check if there are changed Java files
    changed_files = (
        repo.git.diff(commit, next_commit, "***.java", name_only=True)
        .strip()
        .splitlines()
    )

    if not changed_files:
        continue

    diff = repo.git.diff(
        commit,
        next_commit,
        "***.java",
        patch=True,
        unified=0,
        src_prefix="",
        dst_prefix="",
    )

    patch_set = PatchSet(StringIO(diff))

    if not os.path.exists(os.path.join(reports, f"report_{commit.hexsha[:7]}.tar.gz")):
        continue

    with tarfile.open(
        os.path.join(reports, f"report_{commit.hexsha[:7]}.tar.gz"), "r:gz"
    ) as targz:
        targz.extractall(reports, filter="fully_trusted")

    if not os.path.exists(os.path.join(reports, f"report_{commit.hexsha[:7]}.json")):
        continue

    current_violations = report_to_dict(
        os.path.join(reports, f"report_{commit.hexsha[:7]}.json")
    )

    if not current_violations:
        continue

    if not os.path.exists(os.path.join(reports, f"report_{next_commit.hexsha[:7]}.tar.gz")):
        continue

    with tarfile.open(
        os.path.join(reports, f"report_{next_commit.hexsha[:7]}.tar.gz"), "r:gz"
    ) as targz:
        targz.extractall(reports, filter="fully_trusted")

    if not os.path.exists(
        os.path.join(reports, f"report_{next_commit.hexsha[:7]}.json")
    ):
        continue

    next_violations = report_to_dict(
        os.path.join(reports, f"report_{next_commit.hexsha[:7]}.json")
    )

    if not next_violations:
        continue

    for filename, violations in current_violations.items():
        if filename not in changed_files:
            for violation in violations:
                warn_db.append(
                    create_warn(
                        tool="PMD",
                        repo_url=remote_url,
                        commit_sha=commit.hexsha,
                        commit_date=get_iso_commit_date(commit),
                        filepath=filename,
                        violation=violation,
                        label=0,
                    )
                )
        else:
            target_violations = None

            if filename in next_violations.keys():
                target_violations = next_violations[filename]
            else:
                for patch_file in patch_set:
                    if (
                        patch_file.source_file == filename
                        and patch_file.target_file in next_violations.keys()
                    ):
                        target_violations = next_violations[patch_file.target_file]

            if not target_violations:
                continue

            for pair in itertools.product(violations, target_violations):
                if pair[0] == pair[1]:
                    warn_db.append(
                        create_warn(
                            tool="PMD",
                            repo_url=remote_url,
                            commit_sha=commit.hexsha,
                            commit_date=get_iso_commit_date(commit),
                            filepath=filename,
                            violation=pair[0],
                            label=0,
                        )
                    )
                else:
                    v0 = pair[0].copy()
                    v0.pop("beginline", None)
                    v0.pop("endline", None)
                    v1 = pair[1].copy()
                    v1.pop("beginline", None)
                    v1.pop("endline", None)
                    if v0 == v1:
                        warn_db.append(
                            create_warn(
                                tool="PMD",
                                repo_url=remote_url,
                                commit_sha=commit.hexsha,
                                commit_date=get_iso_commit_date(commit),
                                filepath=filename,
                                violation=pair[0],
                                label=0,
                            )
                        )

    os.remove(os.path.join(reports, f"report_{commit.hexsha[:7]}.json"))
    os.remove(os.path.join(reports, f"report_{next_commit.hexsha[:7]}.json"))

df = pd.DataFrame.from_records(warn_db)
col_names = list(df.columns)
if (
    "warning_type" in col_names
    and "warning_msg" in col_names
    and "filename" in col_names
):
    df = df.drop_duplicates(
        subset=["warning_type", "warning_msg", "filename"], keep="last"
    )
if "warning_msg" in col_names:
    df = df[~df["warning_msg"].isin(tp_warn_msgs)]

logger.info(f"Found {len(df)} PMD FP warning{'s' if len(df) > 1 else ''}.")
if len(df) < 1:
    logger.warning("No output was generated by PMD FP warning finder.")
    exit()

df.to_csv(output, encoding="utf-8", index=False)
